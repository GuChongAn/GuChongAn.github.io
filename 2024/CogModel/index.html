<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:fb="https://www.facebook.com/2008/fbml" xmlns:og="http://ogp.me/ns#">
 <head>
  <title>
   [Read Paper] CogVLM&amp;CogAgent 两篇视觉大语言模型 - Chongan's website
  </title>
  <!-- Using the latest rendering mode for IE -->
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <link href="../../image/favicon.ico" rel="icon"/>
  <link href="../../css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css"/>
  <link href="../../css/vs.css" rel="stylesheet" type="text/css"/>
  <link href="../../css/style.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <!-- navbar -->
  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
   <div class="container">
    <div class="navbar-header">
     <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type="button">
      <span class="sr-only">
       Toggle navigation
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
     </button>
     <a class="navbar-brand" href="https://guchongan.github.io/">
      <img height="32" src="../../image/favicon-32x32.png" width="32"/>
      Gu Chongan's website
     </a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
     <ul class="nav navbar-nav navbar-right">
      <li>
       <a href="https://guchongan.github.io/about">
        <i class="fa fa-question">
        </i>
        <span class="icon-label">
         About
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/projects">
        <i class="fa fa-github">
        </i>
        <span class="icon-label">
         Projects
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/archives">
        <i class="fa fa-th-list">
        </i>
        <span class="icon-label">
         Archives
        </span>
       </a>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="container">
   <div class="row">
    <section id="content">
     <article>
      <header class="page-header">
       <h1>
        <a href="https://guchongan.github.io/2024/[Read Paper] CogVLM&amp;CogAgent 两篇视觉大语言模型" rel="bookmark" title="[Read Paper] CogVLM&amp;CogAgent 两篇视觉大语言模型">
         [Read Paper] CogVLM&amp;CogAgent 两篇视觉大语言模型
        </a>
       </h1>
      </header>
      <div class="entry-content">
       <div class="panel">
        <div class="panel-body">
         <footer class="post-info">
          <span class="published">
           <i class="fa fa-calendar">
           </i>
           <time>
            2024.04.24
           </time>
          </span>
          <span class="label label-default">
           Tags
          </span>
          <html>
           <body>
            <a>
             readpaper
            </a>
           </body>
          </html>
         </footer>
         <!-- /.post-info -->
        </div>
       </div>
       <!-- /.entry-content -->
       <html>
        <body>
         <p>
          清华和智谱发表了CogVLM和CogAgent两篇文章，前者主要是提出了一个视觉大语言模型，后者对前者做了GUI任务的改进以及对高分辨率图像处理的改进，论文地址和代码地址如下，
         </p>
         <ul>
          <li>
           <p>
            Paper
           </p>
           <ul>
            <li>
             <a href="https://arxiv.org/abs/2311.03079">
              CogVLM: Visual Expert for Pretrained Language Models
             </a>
            </li>
            <li>
             <a href="https://arxiv.org/abs/2312.08914">
              CogAgent: A Visual Language Model for GUI Agents
             </a>
            </li>
           </ul>
          </li>
          <li>
           <p>
            Code
           </p>
           <ul>
            <li>
             <a href="https://github.com/THUDM/CogVLM">
              CogVLM
             </a>
            </li>
           </ul>
          </li>
         </ul>
         <p>
          接下来先看CogVLM: Visual Expert for Pretrained Language Models这篇文章，
         </p>
         <h2>
          [arXiv] CogVLM: Visual Expert for Pertrained Language Models
         </h2>
         <p>
          <img alt="2.png" src="../../image/2024/2.png"/>
         </p>
         <p>
          文章先讲了一个从
          <strong>
           shallow alignment
          </strong>
          到
          <strong>
           deep fusion
          </strong>
          的故事，前者我还需要再读一下对应的论文，我大概的理解是shallow alignment在固定基座模型参数的情况下，想办法把视觉能力加入，而这篇文章所谓的deep fusion改变了基座模型内部的处理过程和参数。
         </p>
         <p>
          如上图所示，只有紫色的部分在训练过程中参数会发生变化，本文和其他模型最主要的不同就在于在Language model中加入的visual expert结构，其实就是在每个block中加了一个处理视觉特征的分支，但是文章中没有具体解释它这个分支是如何加上去的，比如在计算过程中，我如何区分谁是图像特征，谁是文本特征等等，所以需要看下代码实现，在CogVLM仓库下的
          <code>
           utils/models/cogvlm._model.py
          </code>
          文件中，有如下代码，
         </p>
         <div class="highlight">
          <pre><span></span><span class="kn">from</span> <span class="nn">sat.model.official.llama_model</span> <span class="kn">import</span> <span class="n">LLaMAModel</span>
<span class="k">class</span> <span class="nc">CogVLMModel</span><span class="p">(</span><span class="n">LLaMAModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"eva"</span><span class="p">,</span> <span class="n">ImageMixin</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">del_mixin</span><span class="p">(</span><span class="s2">"mlp"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"mlp"</span><span class="p">,</span> <span class="n">LlamaVisionExpertFCMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">inner_hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">del_mixin</span><span class="p">(</span><span class="s2">"rotary"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"rotary"</span><span class="p">,</span> <span class="n">LlamaVisionExpertAttnMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
</pre>
         </div>
         <p>
          这里用了一个奇怪的库
          <code>
           sat
          </code>
          ，搜索到本文单位的另一个库
          <a href="https://github.com/THUDM/SwissArmyTransformer/tree/main">
           SwissArmyTransformer
          </a>
          ，简单阅读README后得知，这个库提供了一系列的大语言模型以及对模型的修改办法，所以CogVLM实际上是在LLaMA的基础上修改来的，LLaMA来自论文
          <a href="https://arxiv.org/pdf/2302.13971.pdf">
           LLaMA: Open and Efficient Foundation Language Models
          </a>
          ，对应sat中的类的代码如下，
         </p>
         <div class="highlight">
          <pre><span></span><span class="k">class</span> <span class="nc">LLaMAModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layernorm</span><span class="o">=</span><span class="n">RMSNorm</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">silu</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span> <span class="n">layernorm</span><span class="o">=</span><span class="n">layernorm</span><span class="p">,</span> <span class="n">activation_func</span><span class="o">=</span><span class="n">activation_func</span><span class="p">,</span> <span class="n">init_method_std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"rotary"</span><span class="p">,</span> <span class="n">RotaryMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"lm"</span><span class="p">,</span> <span class="n">LMMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"mlp"</span><span class="p">,</span> <span class="n">LLaMAMlpMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">inner_hidden_size</span><span class="p">))</span>
</pre>
         </div>
         <p>
          所以LLaMA在此处的实现逻辑实际就是在BaseModel的基础上，添加了
          <code>
           rotary
          </code>
          ，
          <code>
           lm
          </code>
          ，
          <code>
           mlp
          </code>
          三个模块，对应LLaMA的论文可知，
         </p>
         <ul>
          <li>
           <code>
            rotary
           </code>
           对应文中的
           <strong>
            Rotary Embeddings
           </strong>
           ，就是把整体的位置编码删去，然后在没层前面加一个Rotary的位置编码（RoPE），当然实际上这里代码中的rotary表示其实是attention层+RoPE
          </li>
          <li>
           <code>
            lm
           </code>
           我猜测对应最后的输出位置的一个Linear层，因为它的forward函数定义为
           <code>
            final_forward
           </code>
           ，当然它也不重要，主要应该是为了加速
          </li>
          <li>
           <code>
            mlp
           </code>
           就是transformer block中跟在attention层后面的mlp层，这里用了文中的
           <strong>
            SwiGLU
           </strong>
           激活函数
          </li>
         </ul>
         <p>
          理清LLaMAmodel后，再来看CogVLM的代码就清除多了，其实就是在LLaMA的基础上作了三部分更改，首先是在模型的最前面，对应LLaMA的word embedding步骤的地方加入了Vit模型处理图像数据，对应图(a) concat之前的部分，
         </p>
         <div class="highlight">
          <pre><span></span><span class="k">class</span> <span class="nc">ImageMixin</span><span class="p">(</span><span class="n">BaseMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">word_embedding_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">output_cross_layer</span><span class="p">,</span> <span class="o">**</span><span class="n">kw_args</span><span class="p">):</span>
        <span class="n">vision_inputs</span> <span class="o">=</span> <span class="o">...</span>
        <span class="k">if</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">vision_inputs</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">word_embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">image_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vit_model</span><span class="p">(</span><span class="o">**</span><span class="n">vision_inputs</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_proj</span><span class="p">(</span><span class="n">image_emb</span><span class="p">)</span>

        <span class="n">image_embed_mask</span> <span class="o">=</span> <span class="n">kw_args</span><span class="p">[</span><span class="s1">'image_embed_mask'</span><span class="p">]</span>
        <span class="n">word_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">word_embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">word_embedding</span><span class="p">[</span><span class="n">image_embed_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">boi</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image_emb</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">image_emb</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eoi</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">image_emb</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">image_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">word_embedding</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
</pre>
         </div>
         <p>
          然后是更改了transformer的主体block，FFN层和注意力层的修改是类似的，所以这里只摘录FC层对应的代码，对应图(b)
         </p>
         <div class="highlight">
          <pre><span></span><span class="k">class</span> <span class="nc">LlamaVisionExpertFCMixin</span><span class="p">(</span><span class="n">BaseMixin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">mlp_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">,</span> <span class="o">**</span><span class="n">kw_args</span><span class="p">):</span>
        <span class="n">language_hidden_state</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[</span><span class="o">~</span><span class="n">vision_expert_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()]</span>
        <span class="n">language_intermediate_parallel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">(</span><span class="n">mixin_self</span><span class="o">.</span><span class="n">gate_proj</span><span class="p">[</span><span class="n">kw_args</span><span class="p">[</span><span class="s1">'layer_id'</span><span class="p">]](</span><span class="n">language_hidden_state</span><span class="p">))</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_h_to_4h</span><span class="p">(</span><span class="n">language_hidden_state</span><span class="p">)</span>
        <span class="n">output</span><span class="p">[</span><span class="o">~</span><span class="n">vision_expert_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_4h_to_h</span><span class="p">(</span><span class="n">language_intermediate_parallel</span><span class="p">)</span>  <span class="c1"># language_output</span>

        <span class="n">vision_hidden_state</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[</span><span class="n">vision_expert_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()]</span>
        <span class="n">vision_intermediate_parallel</span> <span class="o">=</span> <span class="n">vision_dense_h_to_4h</span><span class="p">(</span><span class="n">vision_hidden_state</span><span class="p">)</span>
        <span class="n">gate_output</span> <span class="o">=</span> <span class="n">vision_gate_proj</span><span class="p">(</span><span class="n">vision_hidden_state</span><span class="p">)</span>

        <span class="n">vision_intermediate_parallel</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation_func</span><span class="p">(</span><span class="n">gate_output</span><span class="p">)</span>
        <span class="n">output</span><span class="p">[</span><span class="n">vision_expert_mask</span><span class="o">.</span><span class="n">bool</span><span class="p">()]</span> <span class="o">=</span> <span class="n">vision_dense_4h_to_h</span><span class="p">(</span><span class="n">vision_intermediate_parallel</span><span class="p">)</span>  <span class="c1"># vision_output</span>
    	<span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
</pre>
         </div>
         <p>
          看到这里其实对模型的机构就大体明白了，没有什么太复杂的处理，只是作者用了个自己的sat库来做实现，导致代码需要细看一下，其实就是用两个vision expert mask来实现每个transformer block中分别对图像数据和文本数据作处理。
         </p>
         <p>
          然后我们来看CogAgent: A Visual Language Model for GUI Agents这篇文章，
         </p>
         <h2>
          [CVPR24] CogAgent: A Visual Language Model for GUI Agents
         </h2>
         <p>
          我一开始是先看的CogAgent这篇，但是觉得它模型的部分没有讲清除，所有又找了CogLVM来看，有了CogLVM的基础后，理解CogAgent的改动就简单多了。
         </p>
         <p>
          <img alt="3.png" src="../../image/2024/3.png"/>
         </p>
         <p>
          如上图所示，Original VLM对应CogVLM，所以本文主要的改动就集中与上图左半边的
          <strong>
           High-Resolution Cross-Module
          </strong>
          ，本文讲的故事是，因为作GUI的任务需要关注微小的文本或者按钮，所以需要高分辨的图像，但是直接输入高分别的图像会导致计算量过大，所以本文提出了这个High-resolution cross module，在具体实现上，文章给出了两个公式，
         </p>
         <div class="math">
          $$
X_i^{'} = MSA(layernorm(X_{in_i})) + X_{in_i}
$$
         </div>
         <div class="math">
          $$
X_{out_i} = MCA(layernorm(X_i^{'}, X_{hi})) + X_i^{'}
$$
         </div>
         <p>
          其中MSA和MCA分别是CogVLM的多头自注意力模块（有visual expert）和多头交叉注意力模块，
          <span class="math">
           $X_{in_i}$
          </span>
          和
          <span class="math">
           $X_{hi}$
          </span>
          分别是低像素分支加上文本的输入以及高像素分支的输入，在MCA中，
          <span class="math">
           $X_{i}^{'}$
          </span>
          别用来计算Query，
          <span class="math">
           $X_{hi}$
          </span>
          被用来计算key和value，按照本文对训练部分的解释，MCA的参数是可训练的，而MSA的参数应该是固定的，和CogVLM一样，我们也来看看代码，
         </p>
         <div class="highlight">
          <pre><span></span><span class="k">class</span> <span class="nc">CogAgentModel</span><span class="p">(</span><span class="n">LLaMAModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">transformer</span><span class="o">=</span><span class="n">transformer</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"eva"</span><span class="p">,</span> <span class="n">ImageMixin</span><span class="p">(</span><span class="n">args</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">del_mixin</span><span class="p">(</span><span class="s2">"mlp"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"mlp"</span><span class="p">,</span> <span class="n">LlamaVisionExpertFCMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">inner_hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">del_mixin</span><span class="p">(</span><span class="s2">"rotary"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"rotary"</span><span class="p">,</span> <span class="n">LlamaVisionExpertAttnMixin</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_attention_heads</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
        
        <span class="n">cross_model</span> <span class="o">=</span> <span class="n">ExternalVisionModel</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">vitclass</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Eva2LargeEncoder</span><span class="p">,</span> <span class="n">image_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cross_image_pix</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_mixin</span><span class="p">(</span><span class="s2">"encoder"</span><span class="p">,</span> <span class="n">cross_model</span><span class="p">)</span>
        
   <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">vision_expert_mask</span><span class="p">,</span> <span class="n">image_embed_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">cross_inputs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_mixin</span><span class="p">(</span><span class="s1">'encoder'</span><span class="p">)(</span><span class="o">**</span><span class="n">cross_inputs</span><span class="p">)</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">'encoder_outputs'</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">'cross_attention_mask'</span><span class="p">]</span> <span class="o">=</span> <span class="n">cross_inputs</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span> 

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">vision_expert_mask</span><span class="o">=</span><span class="n">vision_expert_mask</span><span class="p">,</span> <span class="n">image_embed_mask</span><span class="o">=</span><span class="n">image_embed_mask</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre>
         </div>
         <p>
          在CogVLM的基础上，CogAgent只添加了一个cross_model，就是上图中的那个High-resolution Image Encoder，一开始有点疑惑，后面发现CrossAttention在sat库中有实现，所以上述代码中的
          <code>
           encoder_outputs
          </code>
          和
          <code>
           cross_attention_mask
          </code>
          会被sat库中的代码使用，我才反应过来，正常的transformer的decoder部分也是个cross attention，cross的是自己原本的encoder的部分，这就解释得通了，CogAgent的代码只是把decoder会使用的encoder的output换成了High-resolution Image Encoder的输出。
         </p>
         <h2>
          总结
         </h2>
         <p>
          可能是我相关领域的文章读太少了，而这两篇文章默认读者了解很多基础知识，所以读起来感觉不是很好，但是在看了代码之后，还是大概搞懂了这两篇文章作了什么。其次就是这两篇文章的代码都大量使用了自己的库（sat），我看sat在github上的star也不是特别多，所以我觉得它代码写的挺冗杂的。
         </p>
         <p>
          接下来计划跟这李沐的论文精读读一下LLM相关的文章。
         </p>
        </body>
       </html>
      </div>
      <hr/>
      <div class="dotted-links">
       <p class="align-center">
        For comments, please send me
        <a href="hu197136@gmail.com">
         <i class="fa fa-envelope-o">
         </i>
         an email
        </a>
        .
       </p>
      </div>
     </article>
    </section>
   </div>
  </div>
  <footer>
   <div class="container">
    <hr/>
    <div class="row">
     <div class="col-xs-10">
      © 2024-2024 Gu Chongan
     </div>
     <div class="col-xs-2">
      <p class="pull-right">
       <i class="fa fa-arrow-up">
       </i>
       <a href="#">
        Back to top
       </a>
      </p>
     </div>
    </div>
   </div>
  </footer>
  <script src="../../css/jquery-2.2.4.min.js">
  </script>
  <script src="../../css/bootstrap.min.js">
  </script>
  <script type="text/x-mathjax-config">
   var articlemathId = document.getElementById("articleContent");
	var commentmathId = document.getElementById("commentlist-container");
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'] ], //行内公式
			displayMath: [ ['$$','$$'] ], //行间公式
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //渲染时跳过的html标签
			ignoreClass: "summary", //忽略的class
		}
	});
	MathJax.Hub.Queue(["Typeset", MathJax.Hub, articlemathId, commentmathId]); //指定渲染的html块，可以为多个
  </script>
  <script src="https://cdn.bootcss.com/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
 </body>
</html>
