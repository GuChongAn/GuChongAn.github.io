<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:fb="https://www.facebook.com/2008/fbml" xmlns:og="http://ogp.me/ns#">
 <head>
  <title>
   Chongan's website
  </title>
  <!-- Using the latest rendering mode for IE -->
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <link href="./image/favicon.ico" rel="icon"/>
  <link href="./css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css"/>
  <link href="./css/vs.css" rel="stylesheet" type="text/css"/>
  <link href="./css/style.css" rel="stylesheet" type="text/css"/>
  <link href="https://eli.thegreenplace.net/feeds/all.atom.xml" rel="alternate" title="Eli Bendersky's website ATOM Feed" type="application/atom+xml"/>
 </head>
 <body>
  <!-- navbar -->
  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
   <div class="container">
    <div class="navbar-header">
     <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type="button">
      <span class="sr-only">
       Toggle navigation
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
     </button>
     <a class="navbar-brand" href="https://guchongan.github.io/">
      <img height="32" src="./image/favicon-32x32.png" width="32"/>
      Gu Chongan's website
     </a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
     <ul class="nav navbar-nav navbar-right">
      <li>
       <a href="https://guchongan.github.io/about">
        <i class="fa fa-question">
        </i>
        <span class="icon-label">
         About
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/projects">
        <i class="fa fa-github">
        </i>
        <span class="icon-label">
         Projects
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/archives">
        <i class="fa fa-th-list">
        </i>
        <span class="icon-label">
         Archives
        </span>
       </a>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="container">
   <div class="row">
    <article>
     <h1>
      <a href="https://guchongan.github.io/2024/CVPR-ICCV-underwater">
       [Read Paper] CVPR/ICCV/WACV23 underwater相关文章总结
      </a>
     </h1>
     <span class="published">
      <i class="fa fa-calendar">
      </i>
      <time>
       2024.04.18
      </time>
     </span>
     <br/>
     <br/>
     <div class="entry-content">
      <html>
       <body>
        <p>
         在ICCV/CVPR/WACV 23年的Main Conference发表论文列表以underwater和water为关键词搜索，可知这三个会议在23年有5篇水下相关的文章发表,
        </p>
        <ol>
         <li>
          ICCV
         </li>
        </ol>
        <ul>
         <li>
          <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Lian_WaterMask_Instance_Segmentation_for_Underwater_Imagery_ICCV_2023_paper.html">
           WaterMask: Instance Segmentation for Underwater Imagery
          </a>
          （水下图像+分割）
         </li>
         <li>
          <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.html">
           Self-supervised Monocular Underwater Depth Recovery, Image Restoration, and a Real-sea Video Dataset
          </a>
          （水下图像+场景深度估计+增强/恢复）
         </li>
         <li>
          <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.html">
           RFD-ECNet: Extreme Underwater Image Compression with Reference to Feature Dictionary
          </a>
          （水下图像+图像压缩）
         </li>
        </ul>
        <ol start="2">
         <li>
          CVPR
         </li>
        </ol>
        <ul>
         <li>
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Contrastive_Semi-Supervised_Learning_for_Underwater_Image_Restoration_via_Reliable_Bank_CVPR_2023_paper.html">
           Contrastive Semi-Supervised Learning for Underwater Image Restoration via Reliable Bank
          </a>
          （水下图像+增强/恢复）
         </li>
         <li>
          <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Indiscernible_Object_Counting_in_Underwater_Scenes_CVPR_2023_paper.html">
           Indiscernible Object Counting in Underwater Scenes
          </a>
          （水下图像+目标识别）
         </li>
        </ul>
        <ol start="3">
         <li>
          WACV（无）
         </li>
        </ol>
        <p>
         显然，单纯的水下图像增强只有一篇文章，而在水下图像的数据集上进行其他任务，例如场景深度估计、分割、目标识别等，相对更好发文章，接下来先读有增强部分的两篇，
        </p>
        <h2>
         [CVPR23] Contrastive Semi-Supervised Learning for Underwater Image Restoration via Reliable Bank
        </h2>
        <p>
         <img alt="" src="../image/2024/1.png"/>
        </p>
        <p>
         文章在模型部分主要讲了三个东西，
        </p>
        <ul>
         <li>
          学生教师网络
         </li>
        </ul>
        <p>
         就是比较常见的学生教师网络模型，有一个学生网络，一个教师网络，学生网络通过与教师网络相关的信息更新，教师网络通过exponential moving average（EMA）更新，公式如下
        </p>
        <div class="math">
         $$
\theta_t = \eta\theta_t + (1-\eta)\theta_s
$$
        </div>
        <p>
         其中
         <span class="math">
          \(\theta_t\)
         </span>
         和
         <span class="math">
          \(\theta_s\)
         </span>
         分别是学生和教师网络的权重，
         <span class="math">
          \(\eta\)
         </span>
         是控制更新的超参
        </p>
        <p>
         学生网络通过损失函数约束，优化器反向传播更新，公式如下
        </p>
        <div class="math">
         $$
L_{overall} = L_{sup} + \beta_1L_{per} + \beta_2L_{grad} + L_{un} + \gamma L_{cr}
$$
        </div>
        <p>
         其实就是有监督的L1损失、感知损失、梯度损失加上无监督的教师损失和对比损失，分别对应接下来的两个部分，
        </p>
        <ul>
         <li>
          可信赖银行
         </li>
        </ul>
        <p>
         这篇文章所谓reliable bank的思路有些类似于之前看过的有的文章中的memory模块的思路，正常的教师学生网络应该是用教师网络的输出直接去约束学生网络的输出，其实就是两者作个L1损失，但是本文作者认为教师网络的输出有可能会有错误的地方，所以用了个bank把之前教师网络输出中最好的几张图存下来作为学生网络的参考
        </p>
        <ul>
         <li>
          对比学习
         </li>
        </ul>
        <p>
         经典的无监督学习方法，损失函数是个分数，分子部分是学生网络对无标签输入的输出和bank中伪标签的感知损失，分母部分是学生网络对无标签输入的输出和对应无标签输入的感知损失，其实就是让学生网络的输出和bank的记录更近，和原始输入更远
        </p>
        <p>
         文章思路很简单，就是想办法把无标签的数据用上，学生教师网络只是个框架，bank和对比学习只是把无标签数据更好用上的方法。第一遍通读下来，有疑问的地方可能有两个，
        </p>
        <ul>
         <li>
          data augmentation
         </li>
        </ul>
        <p>
         本文在大部分的输入前都作了个数据增强，并在ablation部分说明了数据增强的必要性，反应到代码中，有标签的数据只做了旋转，无标签的数据在数据读取的部分经过了如下函数，
        </p>
        <div class="highlight">
         <pre><span></span><span class="k">def</span> <span class="nf">data_aug</span><span class="p">(</span><span class="n">images</span><span class="p">):</span>
    <span class="n">blurring_image</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">()</span>
    <span class="n">color_jitter</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">()</span>
    <span class="n">strong_aug</span> <span class="o">=</span> <span class="n">images</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.8</span><span class="p">:</span>
        <span class="n">strong_aug</span> <span class="o">=</span> <span class="n">color_jitter</span><span class="p">(</span><span class="n">strong_aug</span><span class="p">)</span>
    <span class="n">strong_aug</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomGrayscale</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">strong_aug</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
        <span class="n">strong_aug</span> <span class="o">=</span> <span class="n">blurring_image</span><span class="p">(</span><span class="n">strong_aug</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">strong_aug</span>
</pre>
        </div>
        <ul>
         <li>
          训练步骤
         </li>
        </ul>
        <p>
         本文没有详细介绍它的训练过程，但本文又有无标签数据又有有标签数据，又是学生教师两个网络，所以我认为还是需要明确一下训练步骤，在阅读代码后，我总结如下，bank在实际实现上就是把那些图存在了一个文件夹下面，
        </p>
        <div class="highlight">
         <pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">label_img</span><span class="p">,</span> <span class="o">...</span><span class="p">),</span> <span class="p">(</span><span class="n">unlabel_img</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
		<span class="c1"># teacher ouput</span>
        <span class="n">O_t</span> <span class="o">=</span> <span class="n">model_t</span><span class="p">(</span><span class="n">unblabel_img</span><span class="p">)</span>
        <span class="c1"># student output</span>
        <span class="n">O_s_l</span> <span class="o">=</span> <span class="n">model_s</span><span class="p">(</span><span class="n">label_img</span><span class="p">)</span>
        <span class="n">O_s_ul</span> <span class="o">=</span> <span class="n">model_s</span><span class="p">(</span><span class="n">unlabel_img</span><span class="p">)</span>
        
        <span class="c1"># supervised loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">L1</span><span class="p">(</span><span class="n">O_s_l</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span> <span class="o">+</span> <span class="n">Lper</span><span class="p">(</span><span class="n">O_s_l</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span> <span class="o">+</span> <span class="n">Lgrad</span><span class="p">(</span><span class="n">O_s_l</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>
        
        <span class="c1"># unsupervised loss</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">get_bank</span><span class="p">(</span><span class="n">O_t</span><span class="p">)</span> <span class="c1"># update bank</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">L1</span><span class="p">(</span><span class="n">O_s_ul</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">Lcontra</span><span class="p">(</span><span class="n">O_s_ul</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
</pre>
        </div>
        <ul>
         <li>
          Illumination Map
         </li>
        </ul>
        <p>
         本文模型有两个输出，除了正常的水下图像外，还有个illumination map，但是本文美解释该图是如何生成的，只抛了个引用[55]Ye, Tian, et al. Underwater Light Field Retention : Neural Rendering for Underwater Imaging.我扫了一眼这篇文章以及代码，其实就是多次高斯模糊再过个log后和原本的图相加，
        </p>
        <div class="highlight">
         <pre><span></span><span class="k">def</span> <span class="nf">luminance_estimation</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">sigma_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">90</span><span class="p">]</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>
    <span class="n">illuminance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">sigma</span> <span class="ow">in</span> <span class="n">sigma_list</span><span class="p">:</span>
        <span class="n">illuminance1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">GaussianBlur</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">sigma</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
        <span class="n">illuminance1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">illuminance1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span>
        <span class="n">illuminance</span> <span class="o">=</span> <span class="n">illuminance</span> <span class="o">+</span> <span class="n">illuminance1</span>
    <span class="n">illuminance</span> <span class="o">=</span> <span class="n">illuminance</span> <span class="o">/</span> <span class="mi">3</span>
    <span class="n">L</span> <span class="o">=</span> <span class="p">(</span><span class="n">illuminance</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">illuminance</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">illuminance</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">illuminance</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">L</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">L</span>
</pre>
        </div>
        <p>
         我的理解是在这样的计算下，所有的边缘和纹理信息都被模糊调了，剩下的就只有光照信息了
        </p>
        <h2>
         [ICCV23] Self-supervised Monocular Underwater Depth Recovery, Image Restoration, and a Real-sea Video Dataset
        </h2>
       </body>
      </html>
     </div>
    </article>
    <hr class="style-eight"/>
    <h3>
     Recent posts
    </h3>
    <table class="archive-list">
     <tbody>
      <tr>
       <td style="padding-right: 10px">
        2024.04.18:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024/CVPR-ICCV-underwater">
         [Read Paper] CVPR/ICCV/WACV23 underwater相关文章总结
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.04.08:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024/myBlogPlan">
         我的博客规划以及学习安排
        </a>
       </td>
      </tr>
     </tbody>
    </table>
    <br/>
    See
    <a href="https://guchongan.github.io/archives">
     Archives
    </a>
    for a full list.
   </div>
  </div>
  <footer>
   <div class="container">
    <hr/>
    <div class="row">
     <div class="col-xs-10">
      © 2024-2024 Gu Chongan
     </div>
     <div class="col-xs-2">
      <p class="pull-right">
       <i class="fa fa-arrow-up">
       </i>
       <a href="#">
        Back to top
       </a>
      </p>
     </div>
    </div>
   </div>
  </footer>
  <script src="./css/jquery-2.2.4.min.js">
  </script>
  <script src="./css/bootstrap.min.js">
  </script>
  <script type="text/x-mathjax-config">
   var articlemathId = document.getElementById("articleContent");
	var commentmathId = document.getElementById("commentlist-container");
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'] ], //行内公式
			displayMath: [ ['$$','$$'] ], //行间公式
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //渲染时跳过的html标签
			ignoreClass: "summary", //忽略的class
		}
	});
	MathJax.Hub.Queue(["Typeset", MathJax.Hub, articlemathId, commentmathId]); //指定渲染的html块，可以为多个
  </script>
  <script src="https://cdn.bootcss.com/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
 </body>
</html>
