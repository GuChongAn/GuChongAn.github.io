<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:fb="https://www.facebook.com/2008/fbml" xmlns:og="http://ogp.me/ns#">
 <head>
  <title>
   Chongan's website
  </title>
  <!-- Using the latest rendering mode for IE -->
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <link href="./image/favicon.ico" rel="icon"/>
  <link href="./css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css"/>
  <link href="./css/vs.css" rel="stylesheet" type="text/css"/>
  <link href="./css/style.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <!-- navbar -->
  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
   <div class="container">
    <div class="navbar-header">
     <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type="button">
      <span class="sr-only">
       Toggle navigation
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
     </button>
     <a class="navbar-brand" href="https://guchongan.github.io/">
      <img height="32" src="./image/favicon-32x32.png" width="32"/>
      Gu Chongan's website
     </a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
     <ul class="nav navbar-nav navbar-right">
      <li>
       <a href="https://guchongan.github.io/about">
        <i class="fa fa-question">
        </i>
        <span class="icon-label">
         About
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/projects">
        <i class="fa fa-github">
        </i>
        <span class="icon-label">
         Projects
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/archives">
        <i class="fa fa-th-list">
        </i>
        <span class="icon-label">
         Archives
        </span>
       </a>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="container">
   <div class="row">
    <article>
     <h1>
      <a href="https://guchongan.github.io/2024\1118-KGCOT">
       [Read Paper] 11.18-12.24 论文阅读（KG-COT、BloombergGPT、MMVQA）
      </a>
     </h1>
     <span class="published">
      <i class="fa fa-calendar">
      </i>
      <time>
       2024.12.24
      </time>
     </span>
     <br/>
     <br/>
     <div class="entry-content">
      <html>
       <body>
        <p>
         看了IJCAI 24的几篇KGQA和多模态QA的文章，
        </p>
        <ul>
         <li>
          <a href="https://www.ijcai.org/proceedings/2024/734">
           KG-CoT: Chain-of-Thought Prompting of Large Language Models over Knowledge Graphs for Knowledge-Aware Question Answering
          </a>
          （IJCAI 24）
         </li>
         <li>
          <a href="https://www.ijcai.org/proceedings/2024/690">
           MMVQA: A Comprehensive Dataset for Investigating Multipage Multimodal Information Retrieval in PDF-based Visual Question Answering
          </a>
          （IJCAI 24）
         </li>
         <li>
          <a href="https://www.ijcai.org/proceedings/2024/659">
           Enhancing Multimodal Knowledge Graph Representation Learning through Triple Contrastive Learning
          </a>
          （IJCAI 24）
         </li>
        </ul>
        <p>
         然后看了彭博社提出的金融LLM，
        </p>
        <ul>
         <li>
          <a href="https://arxiv.org/abs/2303.17564">
           BloombergGPT: A Large Language Model for Finance
          </a>
          （arXiv 2303）
         </li>
        </ul>
        <h2>
         [IJCAI 24] KG-CoT: Chain-of-Thought Prompting of Large Language Models over Knowledge Graphs for Knowledge-Aware Question Answering
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         我一开始以为这篇文章没在KGQA的数据集上做，结果被题目骗了，这就是篇KGQA的文章，所以它的思路和其他KGQA的思路是一样的，
        </p>
        <ul>
         <li>
          LLM特定知识缺乏，幻觉 （Lack of Responsible Factual Knowledge）
         </li>
         <li>
          Cognition Gap with Knowledge Retrievers（query -&gt; knowledge通过相似度，但是相似度不保证有用）
         </li>
        </ul>
        <h4>
         2）方法
        </h4>
        <p>
         <img alt="image-20241122170314173" src="../image/2024/image-20241122170314173.png"/>
        </p>
        <p>
         如上图所示，本文可以分为三步（两步）
        </p>
        <ul>
         <li>
          Graph Reasoning
         </li>
        </ul>
        <p>
         作者训了个小的Graph Reasoning model，具体其实就如上图所示
        </p>
        <ul>
         <li>
          Reasoning Path Generation
         </li>
        </ul>
        <p>
         就是根据前一步的知识图谱推理模型生成推理路径
        </p>
        <ul>
         <li>
          Joint Reasoning
         </li>
        </ul>
        <p>
         把推理路径和问题拼一起问LLM答案
        </p>
        <h4>
         3）实验
        </h4>
        <ul>
         <li>
          数据集：WebQSP、CWQ、SimpleQuestions、WebQuestions
         </li>
         <li>
          实验结果：
         </li>
        </ul>
        <p>
         <img alt="image-20241122170610059" src="../image/2024/image-20241122170610059.png"/>
        </p>
        <ul>
         <li>
          它在实验中还有一个有意思的点是说他很便宜
         </li>
        </ul>
        <p>
         <img alt="image-20241122170826391" src="../image/2024/image-20241122170826391.png"/>
        </p>
        <h2>
         [IJCAI 24]  MMVQA: A Comprehensive Dataset for Investigating Multipage Multimodal Information Retrieval in PDF-based Visual Question Answering
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         本文主要提出了一个DQA（Document QA）的数据集，这个数据集和之前的数据集主要的不同是它需要multipage的推理
        </p>
        <h4>
         2）方法
        </h4>
        <p>
         本文数据集的生成很简单，如下图，
        </p>
        <p>
         <img alt="image-20241213191954914" src="../image/2024/image-20241213191954914.png"/>
        </p>
        <ul>
         <li>
          首先从PubMed收集一些pdf和xml格式的document
         </li>
         <li>
          然后调chatgpt，分别对parageraph和table/figure格式的问题做生成
         </li>
        </ul>
        <p>
         然后本文提出了DIR（Document Information Retrieval）任务，即输入问题和相关实体，输出问题的目标实体，如下图，
        </p>
        <p>
         <img alt="image-20241213192143744" src="../image/2024/image-20241213192143744.png"/>
        </p>
        <p>
         最后本文提出了几个解决该问题的benchmark方法
        </p>
        <ul>
         <li>
          Multimodal Multi-Page Retriever框架
         </li>
         <li>
          RoI-Based Frameworks
         </li>
         <li>
          Image Patch-Based Frameworks
         </li>
         <li>
          Joint-Grained Retriever
         </li>
        </ul>
        <h4>
         3）实验
        </h4>
        <p>
         主要实验结果如下图，
        </p>
        <p>
         <img alt="image-20241213192413586" src="../image/2024/image-20241213192413586.png"/>
        </p>
        <h2>
         [arXiv 2303] BloombergGPT: A Large Language Model for Finance
        </h2>
        <p>
         读了下这篇论文，感觉虽然工作量很大，但是实际上都是工程性的东西，收集了大量的数据，然后训了个很大的模型，这里主要记录一下在阅读论文时对Tokenizer的问题，回顾一下通用的Token方法
        </p>
        <table>
         <thead>
          <tr>
           <th>
            Method
           </th>
           <th>
            Model
           </th>
          </tr>
         </thead>
         <tbody>
          <tr>
           <td>
            BPE
           </td>
           <td>
            GPT-1/2/3，ChatGLM
           </td>
          </tr>
          <tr>
           <td>
            WordPiece
           </td>
           <td>
            BERT
           </td>
          </tr>
          <tr>
           <td>
            Unigram
           </td>
           <td>
            T5、BloombergGPT
           </td>
          </tr>
         </tbody>
        </table>
        <h4>
         1）分词
        </h4>
        <p>
         所谓Tokenizer，其实就是将输入的句子进行切分的操作，根据切分粒度可以分为，
        </p>
        <ul>
         <li>
          基于词的切分
         </li>
         <li>
          基于字的切分
         </li>
         <li>
          基于subword的切分
         </li>
        </ul>
        <p>
         其中基于subword的切分是目前的主流形式，其实就是高频词依旧是完成的词、低频词会变成有意义的子词，例如dogs会变成[dog,##s]
        </p>
        <h4>
         2）切分流程
        </h4>
        <p>
         通常如下图所示分为4步，
        </p>
        <p>
         <img alt="image-20241214210310656" src="../image/2024/image-20241214210310656.png"/>
        </p>
        <ul>
         <li>
          Normalization：去除停用词，多余的空格，大小写等
         </li>
         <li>
          Pre-tokenization：不同tokenizer的实现不一样，通常就是直接基于空格和标点切分
         </li>
         <li>
          Postprocessor：添加特殊Token等
         </li>
        </ul>
        <h4>
         3）Byte-Pair Encoding（BPE）
        </h4>
        <p>
         BPE的思路其实很简单，在训练阶段，
        </p>
        <ul>
         <li>
          <p>
           首先将所有训练数据按字母分词，形成初始词表（helllo -&gt; h, e, l, l, l, o）
          </p>
         </li>
         <li>
          <p>
           然后按词表2gram统计pair的词频（he 1, el 1, ll 2, lo 1）
          </p>
         </li>
         <li>
          <p>
           然后将频率最高的pair合并为一个词添加到词表中（词表：h, e, l, o, ll）
          </p>
         </li>
         <li>
          <p>
           重复前一步直到词表大小到达设置的结果
          </p>
         </li>
        </ul>
        <p>
         在推理阶段，也是将数据切分为字符，然后按训练阶段得到的词表作最长匹配
        </p>
        <h4>
         4）WordPiece
        </h4>
        <p>
         WordPiece和BPE的思路基本一致，只是不是选择频率最高的pair，而是按下面的公式计算互信息，
        </p>
        <p>
         <img alt="image-20241214220250843" src="../image/2024/image-20241214220250843.png"/>
        </p>
        <p>
         这里的a和b是计划合并的词表中的两个词，这里的思想是一个pair的频率很高，但是其中pair的一部分的频率更高，这时候不一定需要进行该pair的合并。 而如果一个pair的频率很高，并且这个pair的两个部分都是只出现在这个pair中，就说明这个pair很值得合并。
        </p>
        <h4>
         5）Unigram
        </h4>
        <p>
         Unigram分词与BPE和WordPiece不同，是基于一个大词表逐步裁剪成一个小词表。具体来说，在训练阶段，
        </p>
        <ul>
         <li>
          首先将训练数据按单词划分，并统计词频，得到初始词表
         </li>
         <li>
          然后统计初始词表中每个词的子词和对应词频，取前n个词构成最初的大词表
         </li>
         <li>
          统计词表中每个词的概率，转换为Unigram loss：-log(count / total_count)
         </li>
         <li>
          作动态规划（Viterbi算法）找到使得一个词的loss最小的分词路径
         </li>
         <li>
          计算所有词对总体loss的影响，删除影响小的，直到词表大小符合要求
         </li>
        </ul>
        <p>
         在推理阶段，也是将数据按word切分，然后按训练阶段得到的词表作最长匹配
        </p>
        <h2>
         [IJCAI 24] Enhancing Multimodal Knowledge Graph Representation Learning through Triple Contrastive Learning
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         本文实际做的是Knowledge Graph embedding，就是输入一个知识图谱，输出该知识图谱的每个节点和关系，输出这些节点和关系对应的embedding，所以本文解决的问题很简单，
        </p>
        <ul>
         <li>
          单模态方法变多模态
         </li>
         <li>
          构造了一个多模态的知识图谱（每个entity，附有图片和解释）
         </li>
        </ul>
        <p>
         我觉得后者才是本文实际的难点所在
        </p>
        <h4>
         2）方法
        </h4>
        <p>
         如下图所示，
        </p>
        <p>
         <img alt="image-20241224165249312" src="../image/2024/image-20241224165249312.png"/>
        </p>
        <p>
         其实就是在原有的KGE的方法的基础上，加入了其他模态的信息，这个加入的方式是用对比学习来实现的
        </p>
        <h4>
         3）实验
        </h4>
        <p>
         <img alt="image-20241224165423202" src="../image/2024/image-20241224165423202.png"/>
        </p>
       </body>
      </html>
     </div>
    </article>
    <hr class="style-eight"/>
    <h3>
     Recent posts
    </h3>
    <table class="archive-list">
     <tbody>
      <tr>
       <td style="padding-right: 10px">
        2024.12.24:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\1118-KGCOT">
         [Read Paper] 11.18-12.24 论文阅读（KG-COT、BloombergGPT、MMVQA）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.18:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\1110-bestRAG">
         [Read Paper] 11.10-11.18 论文阅读（bestRAG/REANO/MRE）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.16:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\cs229-01-linear-model">
         [CS229 Machine Learning] 01 线性模型
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.16:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\cs229-02-kernal-method">
         [CS229 Machine Learning] 02 生成学习算法、核方法和神经网络
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.15:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\cs229-00-math">
         [CS229 Machine Learning] 00 数学基础回顾（线性代数和概率论）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.10:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\1028-LSTK">
         [Read Paper] 10.28-11.10 论文阅读（LSTK/distant supervision/multi-instance Learning）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.10.28:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0928-chatlaw">
         [Read Paper] 9.28-10.28 论文阅读（chatlaw/Multimodal prove）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.09.28:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0918-BGE">
         [Read Paper] 9.18-9.28 论文阅读（BEG M3/BGE/FiEDLis/ToG/KAG）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.09.18:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0902-RAG">
         [Read Paper] 9.2-9.18 论文阅读（RAG/KICGPT/StructGPT/Seq2SeqKGC/KGLLMTest）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.09.01:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0825-VisualPrompting">
         [Read Paper] 8.25-9.1 论文阅读（Visual Prompting/Dissecting Multimodality/LAION-5B）
        </a>
       </td>
      </tr>
     </tbody>
    </table>
    <br/>
    See
    <a href="https://guchongan.github.io/archives">
     Archives
    </a>
    for a full list.
   </div>
  </div>
  <footer>
   <div class="container">
    <hr/>
    <div class="row">
     <div class="col-xs-10">
      © 2024-2024 Gu Chongan
     </div>
     <div class="col-xs-2">
      <p class="pull-right">
       <i class="fa fa-arrow-up">
       </i>
       <a href="#">
        Back to top
       </a>
      </p>
     </div>
    </div>
   </div>
  </footer>
  <script src="./css/jquery-2.2.4.min.js">
  </script>
  <script src="./css/bootstrap.min.js">
  </script>
  <script type="text/x-mathjax-config">
   var articlemathId = document.getElementById("articleContent");
	var commentmathId = document.getElementById("commentlist-container");
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'] ], //行内公式
			displayMath: [ ['$$','$$'] ], //行间公式
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //渲染时跳过的html标签
			ignoreClass: "summary", //忽略的class
		}
	});
	MathJax.Hub.Queue(["Typeset", MathJax.Hub, articlemathId, commentmathId]); //指定渲染的html块，可以为多个
  </script>
 </body>
</html>
