<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:fb="https://www.facebook.com/2008/fbml" xmlns:og="http://ogp.me/ns#">
 <head>
  <title>
   Chongan's website
  </title>
  <!-- Using the latest rendering mode for IE -->
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <link href="./image/favicon.ico" rel="icon"/>
  <link href="./css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css"/>
  <link href="./css/vs.css" rel="stylesheet" type="text/css"/>
  <link href="./css/style.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <!-- navbar -->
  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
   <div class="container">
    <div class="navbar-header">
     <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type="button">
      <span class="sr-only">
       Toggle navigation
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
     </button>
     <a class="navbar-brand" href="https://guchongan.github.io/">
      <img height="32" src="./image/favicon-32x32.png" width="32"/>
      Gu Chongan's website
     </a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
     <ul class="nav navbar-nav navbar-right">
      <li>
       <a href="https://guchongan.github.io/about">
        <i class="fa fa-question">
        </i>
        <span class="icon-label">
         About
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/projects">
        <i class="fa fa-github">
        </i>
        <span class="icon-label">
         Projects
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/archives">
        <i class="fa fa-th-list">
        </i>
        <span class="icon-label">
         Archives
        </span>
       </a>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="container">
   <div class="row">
    <article>
     <h1>
      <a href="https://guchongan.github.io/2024\1110-bestRAG">
       [Read Paper] 11.10-11.18 论文阅读（bestRAG/REANO/MRE）
      </a>
     </h1>
     <span class="published">
      <i class="fa fa-calendar">
      </i>
      <time>
       2024.11.18
      </time>
     </span>
     <br/>
     <br/>
     <div class="entry-content">
      <html>
       <body>
        <p>
         先看了老师发我的RAG最佳实践的论文，
        </p>
        <ul>
         <li>
          <a href="https://aclanthology.org/2024.emnlp-main.981/">
           Searching for Best Practices in Retrieval-Augmented Generation
          </a>
          （EMNLP 24）
         </li>
        </ul>
        <p>
         然后看了两篇知识图谱+RAG的论文，
        </p>
        <ul>
         <li>
          <a href="https://aclanthology.org/2024.acl-long.115/">
           REANO: Optimising Retrieval-Augmented Reader Models through Knowledge Graph Generation
          </a>
          （ACL 24）
         </li>
         <li>
          <a href="https://aclanthology.org/2024.findings-emnlp.496/">
           TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation
          </a>
          （EMNLP findings 24）
         </li>
        </ul>
        <p>
         然后看了两篇多模态关系抽取（Multimodal Relation Extraction）的两篇文章，
        </p>
        <ul>
         <li>
          [Multimodal Relation Extraction with Efficient Graph Alignment](https://njuhugn.github.io/paper/Multimodal Relation Extraction with Efficient Graph Alignment-Zheng-mm21.pdf)（MM 21）
         </li>
         <li>
          <a href="https://aclanthology.org/2023.acl-short.27/">
           Multimodal Relation Extraction with Cross-Modal Retrieval and Synthesis
          </a>
          （ACL 23）
         </li>
        </ul>
        <h2>
         [EMNLP 24] Searching for Best Practices in Retrieval-Augmented Generation
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         如题所示，就是找到RAG的最佳实践。本文还在discussion的部分讨论了一点多模态，但是感觉有点画蛇添足，虽然我能get到他想讲检索图然后回答比直接生成的好处。
        </p>
        <h4>
         2）方法
        </h4>
        <p>
         <img alt="image-20241112202935569" src="../image/2024/image-20241112202935569.png"/>
        </p>
        <p>
         作者把RAG的流程分为了上图所示的步骤，
        </p>
        <ul>
         <li>
          Retrieval Source（黄色）
         </li>
        </ul>
        <p>
         对要检索资料的处理，可以分为chunking，embedding和vector databse三大块
        </p>
        <ul>
         <li>
          Retrieval（蓝色）
         </li>
        </ul>
        <p>
         从资料中检索出query相关文档，然后排序，打包和总结处理
        </p>
        <ul>
         <li>
          Fine-tune（绿色）
         </li>
        </ul>
        <p>
         微调大模型以使之更好利用检索回来的数据
        </p>
        <ul>
         <li>
          Evaluation（红色）
         </li>
        </ul>
        <p>
         大模型评估
        </p>
        <h4>
         3）实验
        </h4>
        <p>
         本文最后得到了RAG最佳实践的结论，实验结果如下图，
        </p>
        <p>
         <img alt="image-20241112203306565" src="../image/2024/image-20241112203306565.png"/>
        </p>
        <h2>
         [ACL 24] REANO: Optimising Retrieval-Augmented Reader Models through Knowledge Graph Generation
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         本文的逻辑是这样的，
        </p>
        <ul>
         <li>
          Open domain question answering任务需要外部数据（他没提幻觉，然后将使用外部数据归因于任务本身）
         </li>
         <li>
          外部数据的passages之间的关系被之前的方法忽视 -&gt; 使用KG利用passages之间的关系
         </li>
         <li>
          之前的方法直接使用现存的知识图谱，存在incompleteness -&gt; 从检索的passages生成知识图谱
         </li>
        </ul>
        <p>
         有一点点问题是第二和第三条间好像不关联，但是问题不大。本文还给了个图例，
        </p>
        <p>
         &lt;img src="../image/2024/image-20241113154314071.png" alt="image-20241113154314071" style="zoom:67%;" /&gt;
        </p>
        <h4>
         2）方法
        </h4>
        <p>
         <img alt="image-20241113154336842" src="../image/2024/image-20241113154336842.png"/>
        </p>
        <p>
         本文的方法可以分为两个阶段，
        </p>
        <ul>
         <li>
          KG Generator
         </li>
        </ul>
        <p>
         从passages生成知识图谱（本文假设相关的passages已经获得），其实就是关系抽取任务，本文也直接使用了最近的关系抽取方法，只是分了intra-context（一篇passage内做关系抽取）和inter-context（所有passage间作关系抽取，这里其实就是实体识别后查wikidata）
        </p>
        <ul>
         <li>
          Answer Predictor
         </li>
        </ul>
        <p>
         在得到passages生成的KG后，本文先用了个GNN来找到最相关的K个三元组，然后把这K个三元组和在一起作为新的passage和原来的passages一起作最后答案的生成。
        </p>
        <p>
         他这里答案生成用的是Fusion-in-Decoder的模型，就是就是每篇passage和问题拼在一起编码，然后所有passage的编码结果拼在一起解码出最后的答案
        </p>
        <h4>
         3）实验
        </h4>
        <ul>
         <li>
          数据集：Natural Questions (NQ), TriviaQA (TQA), EntityQuestions (EQ), 2WikiMultiHopQA (2WQA)和MuSiQue
         </li>
         <li>
          评价指标：Exact Match (EM)，预测的答案是否能匹配到任何参考答案
         </li>
         <li>
          实验结果：
         </li>
        </ul>
        <p>
         <img alt="image-20241113155125783" src="../image/2024/image-20241113155125783.png"/>
        </p>
        <h2>
         [EMNLP 24] TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         本文虽然也和上面这篇做法是几乎一致的，都是将相关文档转为知识图谱，然后利用知识图谱生成回答，但是对于为什么要转为知识图谱的理由不一样，
        </p>
        <ul>
         <li>
          上文的理由是：利用知识图谱提取passage间的关系
         </li>
         <li>
          本文的理由是：利用知识图谱提取更相关的信息
         </li>
        </ul>
        <h4>
         2）方法
        </h4>
        <p>
         <img alt="image-20241115165151561" src="../image/2024/image-20241115165151561.png"/>
        </p>
        <p>
         本文的方法很简单，和上文的框架基本一致，看上图也能看明白，所以这里不赘述
        </p>
        <h4>
         3）实验
        </h4>
        <p>
         本文的实验有点取巧了，它实际没有在各个数据集上达到sota的结果，但是它只比了对文档的不同处理方式，如下图，
        </p>
        <p>
         <img alt="image-20241115165346817" src="../image/2024/image-20241115165346817.png"/>
        </p>
        <p>
         而没有正经的和其他方法做比较
        </p>
        <h2>
         [MM 21] Multimodal Relation Extraction with Efficient Graph Alignment
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         本文应该是Multimodal Relation Extraction的第一篇文章，也提出了一个数据集。本文提出MRE任务是为了利用image补全noisy social media texts的lack of contexts，具体来说本文举了个例子，
        </p>
        <ul>
         <li>
          sentence：JFK and Obama at Harvard.
         </li>
        </ul>
        <p>
         对于这个句子可以识别出JFK和Obama两个实体（我其实有点疑问为啥没Harvard实体），但是不知道两者间的关系，而实际这个句子隐含的关系应该是两者是校友（Alumni），如果有两者一起穿学士服的照片，这个关系比较好提取
        </p>
        <h4>
         2）方法
        </h4>
        <p>
         本文的方法如下图，
        </p>
        <p>
         <img alt="image-20241118094253457" src="../image/2024/image-20241118094253457.png"/>
        </p>
        <p>
         这个图其实思路很清晰，具体有三步，
        </p>
        <ul>
         <li>
          信息提取
          <ul>
           <li>
            语义信息，就是encode、embedding，只是image是先做目标识别，然后分块做编码
           </li>
           <li>
            结构信息，图像好理解，目标识别然后场景图生成，文本这里用了dependency-based的方法，如下图，
           </li>
          </ul>
         </li>
        </ul>
        <p>
         <img alt="image-20241118094622473" src="../image/2024/image-20241118094622473.png"/>
        </p>
        <ul>
         <li>
          Multimodal 对齐
         </li>
        </ul>
        <p>
         上一步分别得到了语义特征和结构特征，这一步对这两种特征分别做图片和文本的对齐。语义的图片文本对齐就是注意力机制；结构的对齐主要利用了节点的度作为结构特征。
        </p>
        <ul>
         <li>
          特征融合和关系预测
         </li>
        </ul>
        <p>
         就是上图最右边的融合操作，最后做个MLP的分类
        </p>
        <h4>
         3）实验
        </h4>
        <p>
         主要实验结果如下图，
        </p>
        <p>
         <img alt="image-20241118095151665" src="../image/2024/image-20241118095151665.png"/>
        </p>
        <h2>
         [ACL 23] Multimodal Relation Extraction with Cross-Modal Retrieval and Synthesis
        </h2>
        <h4>
         1）问题
        </h4>
        <p>
         和上面这篇文章处理的是同样的任务（MRE），但是思路不一样，这篇文章有点RAG的感觉
        </p>
        <h4>
         2）方法
        </h4>
        <p>
         &lt;img src="../image/2024/image-20241118095548380.png" alt="image-20241118095548380" style="zoom:50%;" /&gt;
        </p>
        <p>
         文本编码、图像编码，然后模态融合，没啥好说的。这里值得注意的是，本文利用输入的文本和图像做了检索（用的Google的API），获得了图像相关的实体信息，以及更多的图像信息，然后把检索到的知识一样做了encode。
        </p>
        <h4>
         3）实验
        </h4>
        <p>
         主要实验结果如下图，
        </p>
        <p>
         <img alt="image-20241118095848772" src="../image/2024/image-20241118095848772.png"/>
        </p>
       </body>
      </html>
     </div>
    </article>
    <hr class="style-eight"/>
    <h3>
     Recent posts
    </h3>
    <table class="archive-list">
     <tbody>
      <tr>
       <td style="padding-right: 10px">
        2024.11.18:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\1110-bestRAG">
         [Read Paper] 11.10-11.18 论文阅读（bestRAG/REANO/MRE）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.16:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\cs229-01-linear-model">
         [CS229 Machine Learning] 01 线性模型
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.15:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\cs229-00-math">
         [CS229 Machine Learning] 00 数学基础回顾（线性代数和概率论）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.11.10:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\1028-LSTK">
         [Read Paper] 10.28-11.10 论文阅读（LSTK/distant supervision/multi-instance Learning）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.10.28:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0928-chatlaw">
         [Read Paper] 9.28-10.28 论文阅读（chatlaw/Multimodal prove）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.09.28:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0918-BGE">
         [Read Paper] 9.18-9.28 论文阅读（BEG M3/BGE/FiEDLis/ToG/KAG）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.09.18:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0902-RAG">
         [Read Paper] 9.2-9.18 论文阅读（RAG/KICGPT/StructGPT/Seq2SeqKGC/KGLLMTest）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.09.01:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0825-VisualPrompting">
         [Read Paper] 8.25-9.1 论文阅读（Visual Prompting/Dissecting Multimodality/LAION-5B）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.08.14:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\SummerPaper">
         6月-8月 Summer vacation 论文阅读总结（Multimodal Graph/QA方向）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.07.22:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0722-ReActGraphRAG">
         [Read Paper] 7.15-7.22 论文阅读（Analogical Reasoning/GraphRAG/ReAct）
        </a>
       </td>
      </tr>
     </tbody>
    </table>
    <br/>
    See
    <a href="https://guchongan.github.io/archives">
     Archives
    </a>
    for a full list.
   </div>
  </div>
  <footer>
   <div class="container">
    <hr/>
    <div class="row">
     <div class="col-xs-10">
      © 2024-2024 Gu Chongan
     </div>
     <div class="col-xs-2">
      <p class="pull-right">
       <i class="fa fa-arrow-up">
       </i>
       <a href="#">
        Back to top
       </a>
      </p>
     </div>
    </div>
   </div>
  </footer>
  <script src="./css/jquery-2.2.4.min.js">
  </script>
  <script src="./css/bootstrap.min.js">
  </script>
  <script type="text/x-mathjax-config">
   var articlemathId = document.getElementById("articleContent");
	var commentmathId = document.getElementById("commentlist-container");
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'] ], //行内公式
			displayMath: [ ['$$','$$'] ], //行间公式
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //渲染时跳过的html标签
			ignoreClass: "summary", //忽略的class
		}
	});
	MathJax.Hub.Queue(["Typeset", MathJax.Hub, articlemathId, commentmathId]); //指定渲染的html块，可以为多个
  </script>
 </body>
</html>
