<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:fb="https://www.facebook.com/2008/fbml" xmlns:og="http://ogp.me/ns#">
 <head>
  <title>
   Chongan's website
  </title>
  <!-- Using the latest rendering mode for IE -->
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <link href="./image/favicon.ico" rel="icon"/>
  <link href="./css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css"/>
  <link href="./css/vs.css" rel="stylesheet" type="text/css"/>
  <link href="./css/style.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <!-- navbar -->
  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
   <div class="container">
    <div class="navbar-header">
     <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type="button">
      <span class="sr-only">
       Toggle navigation
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
     </button>
     <a class="navbar-brand" href="https://guchongan.github.io/">
      <img height="32" src="./image/favicon-32x32.png" width="32"/>
      Gu Chongan's website
     </a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
     <ul class="nav navbar-nav navbar-right">
      <li>
       <a href="https://guchongan.github.io/about">
        <i class="fa fa-question">
        </i>
        <span class="icon-label">
         About
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/projects">
        <i class="fa fa-github">
        </i>
        <span class="icon-label">
         Projects
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/archives">
        <i class="fa fa-th-list">
        </i>
        <span class="icon-label">
         Archives
        </span>
       </a>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="container">
   <div class="row">
    <article>
     <h1>
      <a href="https://guchongan.github.io/2024\0705-MultiModal">
       [Read Paper] 6.28-7.5 论文阅读
      </a>
     </h1>
     <span class="published">
      <i class="fa fa-calendar">
      </i>
      <time>
       2024.07.05
      </time>
     </span>
     <br/>
     <br/>
     <div class="entry-content">
      <html>
       <body>
        <p>
         按照6月27号讨论时候说的，还是先从webQA，MMCoQA那几篇论文往后面找，找到这几篇，
        </p>
        <ul>
         <li>
          <a href="https://arxiv.org/pdf/2406.04292v1">
           VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval
          </a>
          （arXiv 2406，引WebQA)
         </li>
         <li>
          <a href="https://arxiv.org/pdf/2403.04735v1">
           SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM
          </a>
          （arXiv 2403，引WebQA）
         </li>
         <li>
          <a href="https://arxiv.org/pdf/2001.08034v1">
           MANYMODALQA: Modality Disambiguation and QA over Diverse Inputs
          </a>
          （AAAI 20，三模态QA）
         </li>
         <li>
          <a href="https://aclanthology.org/2023.findings-acl.292.pdf">
           Unified Language Representation for Question Answering over Text, Tables, and Images
          </a>
          （ACL findings 23，三模态QA）
         </li>
         <li>
          <a href="https://aclanthology.org/2023.findings-emnlp.626/">
           Unifying Text, Tables, and Images for Multimodal Question Answering
          </a>
          （EMNLP findings 23，三模态QA）
         </li>
        </ul>
        <p>
         然后看了之前讲的那篇知识图谱推理的文章，
        </p>
        <ul>
         <li>
          <a href="https://arxiv.org/abs/2310.01061">
           Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning
          </a>
          （ICLR 24）
         </li>
        </ul>
        <h2>
         [arXiv 24] VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval
        </h2>
        <p>
         本文主要提出了三个东西，
        </p>
        <ul>
         <li>
          VISTA，针对多模态检索的一个数据文本嵌入模型
         </li>
        </ul>
        <p>
         <img alt="image-20240701192646652" src="../image/2024/image-20240701192646652.png"/>
        </p>
        <p>
         说起来其实很简单，就是图像用Vit处理得到编码表示，文本直接过一个Embedding，图里面写作Text Tokenizer
        </p>
        <ul>
         <li>
          两个数据集（IT2I和T2IT）
         </li>
        </ul>
        <p>
         Image&amp;Text to Image（IT2I）数据集，生成方式如下图，
        </p>
        <p>
         <img alt="image-20240701192929370" src="../image/2024/image-20240701192929370.png"/>
        </p>
        <p>
         从一个原图像（Source Image&amp;Text），用GPT和扩散模型生成相应的困难负例。然后是Text To Image&amp;Text （T2IT）数据集，对ShareGPT4V数据集中的每一张图像的对应描述扩写成一段话T，并生成查询Q，然后图像，一段话和查询拼在一起作为数据集。
        </p>
        <ul>
         <li>
          两段式的训练方法
         </li>
        </ul>
        <p>
         显示Cross-Modal Training，用下面这个损失函数，
        </p>
        <p>
         <img alt="image-20240701193330618" src="../image/2024/image-20240701193330618.png"/>
        </p>
        <p>
         其中
         <span class="math">
          $L_{con}$
         </span>
         表示对比损失，这个损失的目的是让Vit输出的
         <span class="math">
          $e_i$
         </span>
         和Text Embedding
         <span class="math">
          $e_i$
         </span>
         尽可能的接近，这段训练中用的数据集是Laion-2B。然后是Multi-Modal Training，用下面这个损失函数，
        </p>
        <p>
         <img alt="image-20240701193507404" src="../image/2024/image-20240701193507404.png"/>
        </p>
        <p>
         其中查询Q和待选C都是前面提出的两个数据集中的数据。
        </p>
        <h2>
         [arXiv 24] SnapNTell: Enhancing Entity-Centric Visual Question Answering with Retrieval Augmented Multimodal LLM
        </h2>
        <p>
         和之前的多篇论文一样，提出了一个数据集SnapNTell，他在文中说自己是提出了一个SnapNTell任务，这个任务要求模型识别出图像的细粒度类别，并根据识别的类别生成深度理解的回答。然后提出了一个框架解决他提出的这个问题，数据集具体如下图，
        </p>
        <p>
         <img alt="image-20240703141552752" src="../image/2024/image-20240703141552752.png"/>
        </p>
        <p>
         <img alt="image-20240702152658336" src="../image/2024/image-20240702152658336.png"/>
        </p>
        <p>
         框架结构如下图，
        </p>
        <p>
         <img alt="image-20240702152710556" src="../image/2024/image-20240702152710556.png"/>
        </p>
        <h2>
         [AAAI 20] MANYMODALQA: Modality Disambiguation and QA over Diverse Inputs
        </h2>
        <p>
         三模态QA（文本，图像和表格，和MMCoQA一样），和之前看的文章一样，提出了一个数据集MMQA，提出了一个方法解决这个数据集，数据集示例如下图，
        </p>
        <p>
         <img alt="image-20240702155205314" src="../image/2024/image-20240702155205314.png"/>
        </p>
        <p>
         和MMCoQA一样，或者说MMCoQA和这篇论文一样，都没没有融合处理三模态，而是先确定问题关于那一个模态，然后用处理该模态的模型回答问题，模型结构如下图，
        </p>
        <p>
         <img alt="image-20240702155317904" src="../image/2024/image-20240702155317904.png"/>
        </p>
        <h2>
         [ACL findings 23] Unified Language Representation for Question Answering over Text, Tables, and Images
        </h2>
        <p>
         思路很简单，就是把表格和图像都转成文本，然后三模态QA就变成了文本QA问题
        </p>
        <p>
         <img alt="image-20240705145740189" src="../image/2024/image-20240705145740189.png"/>
        </p>
        <p>
         具体有几个技术细节，都在上图中可以看到，
        </p>
        <ul>
         <li>
          Global和Local的文本caption生成
         </li>
         <li>
          检索后先排序再把排序后的结果拼起来
         </li>
        </ul>
        <h2>
         [EMNLP findings 23] Unifying Text, Tables, and Images for Multimodal Question Answering
        </h2>
        <p>
         和上文的思路完全一样，框架如下图所示，
        </p>
        <p>
         <img alt="image-20240705150055209" src="../image/2024/image-20240705150055209.png"/>
        </p>
        <p>
         唯一值得注意的是他有个Rationale Generator，是不是可以用知识图谱替代这部分，把三模态数据变成知识图谱，从知识图谱里面抓一条推理路径出来
        </p>
        <h2>
         [ICLR 24] Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning
        </h2>
        <p>
         本文提出了一个RoG（Reasoning on Graphs）的框架，如下图所示，
        </p>
        <p>
         <img alt="image-20240705164301922" src="../image/2024/image-20240705164301922.png"/>
        </p>
        <p>
         主要有两个方面的细节，
        </p>
        <ul>
         <li>
          Planning-Retrieval-Reasoning的过程
         </li>
         <li>
          训练模型的损失函数
         </li>
        </ul>
        <p>
         <img alt="image-20240705164405152" src="../image/2024/image-20240705164405152.png"/>
        </p>
        <p>
         其中前者使得模型可以根据检索出的推理路径得到最后的答案，实际上就是语言模型损失，计算预测下一个词正确的概率。后者使得模型可以得到正确的关系路径，具体公式如下，
        </p>
        <p>
         <img alt="image-20240705164545347" src="../image/2024/image-20240705164545347.png"/>
        </p>
        <p>
         和语言模型的损失类似，只是这里下一个词变成了关系路径中的下一个实体。
        </p>
       </body>
      </html>
     </div>
    </article>
    <hr class="style-eight"/>
    <h3>
     Recent posts
    </h3>
    <table class="archive-list">
     <tbody>
      <tr>
       <td style="padding-right: 10px">
        2024.07.05:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0705-MultiModal">
         [Read Paper] 6.28-7.5 论文阅读
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.07.01:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\plan2406">
         [总结] 2024年6月学习总结
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.06.28:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0628-CVPRbest">
         [Read Paper] 6.21-6.28 论文阅读（CVPRbest/ICLRoutstanding/Coca）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.06.21:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0621-MultiModalQA">
         [Read Paper] 6.14-6.21 论文阅读（CLIP/Multimodal QA）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.06.14:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\0614-VitSwinMAE">
         [Read Paper] 6.7-6.14 论文阅读（ViT/Text Summarization/LangChain）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.06.03:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\InstructLLAMATool">
         [Read Paper] InstruceGPT、LLAMA和Toolformer三篇论文
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.06.02:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\plan2405">
         [总结] 2024年5月学习总结
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.29:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\csapp-4">
         [CSAPP] 第3章 程序的机器级表示
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.16:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\DDPM-LDM">
         [Read Paper] DDPM 和 LDM 两篇扩散模型的论文
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.08:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\TransBertGPT">
         [Read Paper] Transformer + Bert + GPT123 大模型基础论文
        </a>
       </td>
      </tr>
     </tbody>
    </table>
    <br/>
    See
    <a href="https://guchongan.github.io/archives">
     Archives
    </a>
    for a full list.
   </div>
  </div>
  <footer>
   <div class="container">
    <hr/>
    <div class="row">
     <div class="col-xs-10">
      © 2024-2024 Gu Chongan
     </div>
     <div class="col-xs-2">
      <p class="pull-right">
       <i class="fa fa-arrow-up">
       </i>
       <a href="#">
        Back to top
       </a>
      </p>
     </div>
    </div>
   </div>
  </footer>
  <script src="./css/jquery-2.2.4.min.js">
  </script>
  <script src="./css/bootstrap.min.js">
  </script>
  <script type="text/x-mathjax-config">
   var articlemathId = document.getElementById("articleContent");
	var commentmathId = document.getElementById("commentlist-container");
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'] ], //行内公式
			displayMath: [ ['$$','$$'] ], //行间公式
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //渲染时跳过的html标签
			ignoreClass: "summary", //忽略的class
		}
	});
	MathJax.Hub.Queue(["Typeset", MathJax.Hub, articlemathId, commentmathId]); //指定渲染的html块，可以为多个
  </script>
 </body>
</html>
