<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:fb="https://www.facebook.com/2008/fbml" xmlns:og="http://ogp.me/ns#">
 <head>
  <title>
   Chongan's website
  </title>
  <!-- Using the latest rendering mode for IE -->
  <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <link href="./image/favicon.ico" rel="icon"/>
  <link href="./css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
  <link href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css"/>
  <link href="./css/vs.css" rel="stylesheet" type="text/css"/>
  <link href="./css/style.css" rel="stylesheet" type="text/css"/>
 </head>
 <body>
  <!-- navbar -->
  <div class="navbar navbar-default navbar-fixed-top" role="navigation">
   <div class="container">
    <div class="navbar-header">
     <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type="button">
      <span class="sr-only">
       Toggle navigation
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
      <span class="icon-bar">
      </span>
     </button>
     <a class="navbar-brand" href="https://guchongan.github.io/">
      <img height="32" src="./image/favicon-32x32.png" width="32"/>
      Gu Chongan's website
     </a>
    </div>
    <div class="collapse navbar-collapse navbar-ex1-collapse">
     <ul class="nav navbar-nav navbar-right">
      <li>
       <a href="https://guchongan.github.io/about">
        <i class="fa fa-question">
        </i>
        <span class="icon-label">
         About
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/projects">
        <i class="fa fa-github">
        </i>
        <span class="icon-label">
         Projects
        </span>
       </a>
      </li>
      <li>
       <a href="https://guchongan.github.io/archives">
        <i class="fa fa-th-list">
        </i>
        <span class="icon-label">
         Archives
        </span>
       </a>
      </li>
     </ul>
    </div>
   </div>
  </div>
  <div class="container">
   <div class="row">
    <article>
     <h1>
      <a href="https://guchongan.github.io/2024\InstructLLAMATool">
       [Read Paper] InstruceGPT、LLAMA和Toolformer三篇论文
      </a>
     </h1>
     <span class="published">
      <i class="fa fa-calendar">
      </i>
      <time>
       2024.06.03
      </time>
     </span>
     <br/>
     <br/>
     <div class="entry-content">
      <html>
       <body>
        <p>
         按照之前计划，读了三篇大语言模型相关的论文
        </p>
        <ul>
         <li>
          <a href="https://arxiv.org/abs/2302.04761">
           Toolformer: Language Models Can Teach Themselves to Use Tools
          </a>
         </li>
         <li>
          <a href="https://arxiv.org/abs/2302.13971">
           LLaMA: Open and Efficient Foundation Language Models
          </a>
         </li>
         <li>
          <a href="https://arxiv.org/abs/2203.02155">
           Training language models to follow instructions with human feedback
          </a>
          （InstructGPT）
         </li>
        </ul>
        <p>
         我们先来看Toolformer这篇文章，
        </p>
        <h2>
         [arXiv] Toolformer: Language Models Can Teach Themselves to Use Tools
        </h2>
        <p>
         <img alt="image-20240607154047607" src="../image/2024/image-20240607154047607.png"/>
        </p>
        <p>
         Toolformer的思路总结起来其实就一句话，用带Tool调用标记的数据集微调了一个LLM。当然其中还是有很多的技术细节，值得关注地方如下，
        </p>
        <p>
         如上图所示，Toolformer的第一步是生成一个有API调用的数据集（LM Dataset -&gt; LM Dataset with API Calls），上图只是一种宏观的视角，具体来说，第1步是通过还没微调的LLM的完成的，将LM Dataset的数据输入，要求LLM输出带有API Calls的输出，如下图所示，
        </p>
        <p>
         <img alt="image-20240607154737487" src="../image/2024/image-20240607154737487.png"/>
        </p>
        <p>
         有了API Calls，下一步就是执行，然后判断那个调用是有效的，将有效的留下。这个判断通过计算
        </p>
        <div class="math">
         $$
L_i^--L_i^+ \geq \alpha_f
$$
        </div>
        <p>
         来实现，其中
         <span class="math">
          $L_i^-=min(L_i(\beta),L_i(e(c_i,\beta)))$
         </span>
         ，
         <span class="math">
          $L_i^+=L_i(e(c_i,r_i))$
         </span>
         分别表示没有API调用或者仅接受API调用的输入时的损失，以及接受API调用和回复的损失，这个损失通过预测下一个词的概率的交叉熵损失表示，并乘以权重，使得更接近API调用处的权重更大。
        </p>
        <p>
         有了数据集之后就微调，本文在这方面没有什么需要注意的。
        </p>
        <h2>
         Training language models to follow instructions with human feedback
        </h2>
        <p>
         <img alt="image-20240607155855041" src="../image/2024/image-20240607155855041.png"/>
        </p>
        <p>
         大名鼎鼎的InstructGPT论文，遵循了Open AI一贯的写作风格，不像论文反倒像篇技术报告，具体的技术了内容其实就只如上图所示，
        </p>
        <ul>
         <li>
          人工标注数据集
         </li>
        </ul>
        <p>
         他们通过人工标注了一批数据，对于某个问题希望大模型的回复。
        </p>
        <ul>
         <li>
          奖励模型
         </li>
        </ul>
        <p>
         但是只用人工标注花费太大，所以他们训练了个reward model，将大模型对于某个问题的回答输出多次，人工进行排序，将排序结果作为标签，训练一个reward model
        </p>
        <ul>
         <li>
          通过奖励模型作强化学习
         </li>
        </ul>
        <p>
         将LLM对于某个问题的输出输入奖励模型，并把奖励模型的输出作为大模型更新的约束
        </p>
        <p>
         然后就是Open AI一贯的大批量的实验，这里不做赘述
        </p>
        <h2>
         LLaMA: Open and Efficient Foundation Language Models
        </h2>
        <p>
         看完其实才知道LLaMA除了结果和开源外，在模型设计上其实没有什么特别需要关注的地方，文中说对模型架构有三点主要改进，
        </p>
        <ul>
         <li>
          Pre-normalization，在每个子层之前作RMSNorm
         </li>
         <li>
          SwiGLU激活函数，一个相比ReLU更好的激活函数，在负数区间处理更细节
         </li>
         <li>
          Rotary Embeddings，相对位置嵌入，可以更好的处理长输入
         </li>
        </ul>
       </body>
      </html>
     </div>
    </article>
    <hr class="style-eight"/>
    <h3>
     Recent posts
    </h3>
    <table class="archive-list">
     <tbody>
      <tr>
       <td style="padding-right: 10px">
        2024.06.03:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\InstructLLAMATool">
         [Read Paper] InstruceGPT、LLAMA和Toolformer三篇论文
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.06.02:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\plan2405">
         [总结] 2024年5月学习总结
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.29:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\csapp-4">
         [CSAPP] 第3章 程序的机器级表示
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.16:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\DDPM-LDM">
         [Read Paper] DDPM 和 LDM 两篇扩散模型的论文
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.08:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\TransBertGPT">
         [Read Paper] Transformer + Bert + GPT123 大模型基础论文
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.05.01:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\plan2404">
         [总结] 2024年4月学习总结
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.04.24:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\CogModel">
         [Read Paper] CogVLM&amp;CogAgent 两篇视觉大语言模型
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.04.18:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\CVPR-ICCV-underwater">
         [Read Paper] CVPR/ICCV/WACV23 underwater相关文章总结（上）
        </a>
       </td>
      </tr>
      <tr>
       <td style="padding-right: 10px">
        2024.04.08:
       </td>
       <td>
        <a href="http://guchongan.github.io/2024\myBlogPlan">
         我的博客规划以及学习安排
        </a>
       </td>
      </tr>
     </tbody>
    </table>
    <br/>
    See
    <a href="https://guchongan.github.io/archives">
     Archives
    </a>
    for a full list.
   </div>
  </div>
  <footer>
   <div class="container">
    <hr/>
    <div class="row">
     <div class="col-xs-10">
      © 2024-2024 Gu Chongan
     </div>
     <div class="col-xs-2">
      <p class="pull-right">
       <i class="fa fa-arrow-up">
       </i>
       <a href="#">
        Back to top
       </a>
      </p>
     </div>
    </div>
   </div>
  </footer>
  <script src="./css/jquery-2.2.4.min.js">
  </script>
  <script src="./css/bootstrap.min.js">
  </script>
  <script type="text/x-mathjax-config">
   var articlemathId = document.getElementById("articleContent");
	var commentmathId = document.getElementById("commentlist-container");
	MathJax.Hub.Config({
		tex2jax: {
			inlineMath: [ ['$','$'] ], //行内公式
			displayMath: [ ['$$','$$'] ], //行间公式
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code','a'], //渲染时跳过的html标签
			ignoreClass: "summary", //忽略的class
		}
	});
	MathJax.Hub.Queue(["Typeset", MathJax.Hub, articlemathId, commentmathId]); //指定渲染的html块，可以为多个
  </script>
 </body>
</html>
